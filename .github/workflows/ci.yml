
name: MLOps CI Pipeline

on:
  push:
    branches: ["main", "develop"]
  pull_request:
    branches: ["main", "develop"]
  workflow_dispatch:
  schedule:
    # Run daily at 2 AM UTC for continuous monitoring
    - cron: '0 2 * * *'

permissions: write-all

env:
  PYTHON_VERSION: "3.11"
  MLFLOW_TRACKING_URI: "file:./mlruns"

jobs:
  # All-in-One CI Job
  ci-pipeline:
    runs-on: ubuntu-latest
    name: Complete CI Pipeline
    
    outputs:
      should-deploy: ${{ steps.deployment-decision.outputs.should-deploy }}
      model-updated: ${{ steps.check-changes.outputs.model-updated }}
      
    steps:
      # 1. Setup
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install black flake8 pylint bandit safety pytest
          make install
          
      # Setup DVC and pull data files
      - name: Setup DVC and Pull Data
        run: |
          echo "📥 Setting up DVC and pulling data files..."
          pip install dvc
          
          # Initialize DVC (if not already done)
          dvc --version
          
          # For CI/CD, we'll create a sample dataset since DVC remote might not be accessible
          echo "🔧 Creating sample dataset for CI/CD..."
          python -c "
          import pandas as pd
          import numpy as np
          import os
          
          # Create Data directory if it doesn't exist
          os.makedirs('Data', exist_ok=True)
          
          # Generate sample personality dataset for CI
          np.random.seed(42)
          n_samples = 1000
          
          data = {
              'Time_spent_Alone': np.random.randint(0, 12, n_samples),
              'Time_spent_with_family': np.random.randint(0, 12, n_samples),
              'Time_spent_with_friends': np.random.randint(0, 12, n_samples),
              'Anxiety_rating': np.random.randint(0, 12, n_samples),
              'Social_media_usage': np.random.randint(0, 12, n_samples),
              'Personality': np.random.choice(['Introvert', 'Extrovert'], n_samples)
          }
          
          df = pd.DataFrame(data)
          df.to_csv('Data/personality_datasert.csv', index=False)
          print(f'✅ Created sample dataset: {df.shape}')
          print(f'Columns: {list(df.columns)}')
          print(f'Personality distribution: {df[\"Personality\"].value_counts().to_dict()}')
          "
          
          echo "✅ Data setup completed"

      # 2. Code Quality & Security
      - name: Code Quality & Security Checks
        run: |
          echo "🔍 Running code quality and security checks..."
          
          # Auto-format code first
          echo "✨ Auto-formatting code with Black..."
          black *.py App/*.py
          
          # Check if any files were changed by formatting
          if ! git diff --quiet; then
            echo "📝 Code was auto-formatted by Black"
            git config user.name "github-actions[bot]"
            git config user.email "github-actions[bot]@users.noreply.github.com"
            git add *.py App/*.py
            git commit -m "style: auto-format code with Black [skip ci]" || true
          else
            echo "✅ Code is already properly formatted"
          fi
          
          # Linting
          flake8 *.py App/*.py --count --select=E9,F63,F7,F82 --show-source --statistics
          pylint *.py App/*.py --exit-zero --score=yes
          
          # Security checks
          bandit -r *.py App/*.py -f json -o bandit-report.json || true
          safety check --json --output safety-report.json || true
          
          echo "✅ Code quality and security checks completed"

      # 3. Data Validation & Testing
      - name: Data Validation & Testing
        run: |
          echo "🧪 Running data validation and tests..."
          
          # Data validation
          python -c "
          import pandas as pd
          import os
          
          if os.path.exists('Data/personality_datasert.csv'):
              df = pd.read_csv('Data/personality_datasert.csv')
              print(f'✅ Original dataset: {df.shape}')
              assert not df.empty, 'Dataset is empty'
              assert len(df.columns) > 0, 'No columns found'
          else:
              print('⚠️ Original dataset not found')
          "
          
          # Basic tests
          python -c "
          import sys
          sys.path.append('.')
          
          # Test imports
          try:
              import train
              import monitoring
              import data_drift
              import data_synthetic_generator
              import retrain_api
              print('✅ All modules import successfully')
          except ImportError as e:
              print(f'❌ Import failed: {e}')
              sys.exit(1)
          "

      # 4. Model Training & Validation
      - name: Model Training & Validation
        run: |
          echo "🎯 Training and validating model..."
          
          # Ensure data is available before training
          if [ ! -f "Data/personality_datasert.csv" ]; then
            echo "📥 Data file missing, running data setup..."
            make ci-data-setup
          fi
          
          make train
          
          # Validate model outputs
          python -c "
          import os
          import skops.io as sio
          
          model_files = [
              'Model/personality_classifier.skops',
              'Model/label_encoder.skops', 
              'Model/feature_names.skops'
          ]
          
          for file in model_files:
              if os.path.exists(file):
                  print(f'✅ {file} created')
                  try:
                      model = sio.load(file, trusted=sio.get_untrusted_types(file))
                      print(f'✅ {file} loads correctly')
                  except Exception as e:
                      print(f'❌ Error loading {file}: {e}')
                      exit(1)
              else:
                  print(f'❌ {file} not found')
                  exit(1)
          "

      # 5. Data Drift Detection & Monitoring
      - name: Data Drift Detection & Monitoring
        run: |
          echo "🔍 Running drift detection and monitoring checks..."
          
          # Generate synthetic data for testing
          python -c "
          from data_synthetic_generator import adaptiveDriftGenerator
          import os
          
          if os.path.exists('Data/personality_datasert.csv'):
              generator = adaptiveDriftGenerator('Data/personality_datasert.csv')
              synthetic_data = generator.generate_drift_data(n_samples=500)
              synthetic_data.to_csv('Data/synthetic_ctgan_data.csv', index=False)
              print(f'✅ Synthetic data generated: {synthetic_data.shape}')
          "
          
          # Run drift detection
          python -c "
          from data_drift import DataDriftDetector
          import os
          import json
          
          if os.path.exists('Data/synthetic_ctgan_data.csv'):
              detector = DataDriftDetector()
              results = detector.detect_drift('Data/synthetic_ctgan_data.csv')
              
              with open('drift_results.json', 'w') as f:
                  json.dump(results, f, indent=2)
              
              print('📊 Drift Detection Results:')
              for key, value in results.items():
                  print(f'{key}: {value}')
          "

      # 6. Performance Testing
      - name: Performance & Load Testing
        run: |
          echo "⚡ Running performance tests..."
          
          # Model performance benchmark
          python -c "
          import time
          import numpy as np
          import skops.io as sio
          import os
          
          if os.path.exists('Model/personality_classifier.skops'):
              model = sio.load('Model/personality_classifier.skops', 
                              trusted=sio.get_untrusted_types('Model/personality_classifier.skops'))
              
              # Test different batch sizes
              for size in [1, 10, 100, 1000]:
                  X_test = np.random.rand(size, 5)
                  start_time = time.time()
                  predictions = model.predict(X_test)
                  end_time = time.time()
                  
                  duration = end_time - start_time
                  throughput = size / duration if duration > 0 else 0
                  latency = (duration * 1000) / size
                  
                  print(f'Size {size}: {throughput:.2f} pred/sec, {latency:.2f}ms/pred')
                  
                  # Performance thresholds
                  if size == 1000 and throughput < 100:
                      print('⚠️ Performance warning: Low throughput')
          "
          
          # Test app startup
          timeout 30 python App/app.py &
          APP_PID=$!
          sleep 15
          
          # Test if app is accessible
          curl -f http://localhost:7860 || echo "⚠️ App not accessible"
          
          # Cleanup
          kill $APP_PID || true

      # 7. Docker Build & Test
      - name: Docker Build & Testing
        run: |
          echo "🐳 Building and testing Docker images..."
          
          # Build main app image
          docker build -t mlops-app:test .
          
          # Build retrain image
          docker build -f Dockerfile.retrain -t mlops-retrain:test .
          
          # Test main container
          docker run -d --name test-app -p 7861:7860 mlops-app:test
          sleep 20
          
          # Test container health
          if docker ps | grep test-app; then
              echo "✅ Main container running"
              curl -f http://localhost:7861 || echo "⚠️ Container not accessible"
          else
              echo "❌ Container failed to start"
              docker logs test-app
          fi
          
          # Cleanup
          docker stop test-app || true
          docker rm test-app || true

      # 8. Integration Testing
      - name: Integration Testing
        run: |
          echo "🔗 Running integration tests..."
          
          # Start monitoring in background
          python monitoring.py &
          MONITORING_PID=$!
          
          # Start retrain API
          python -m uvicorn retrain_api:app --host 0.0.0.0 --port 8001 &
          RETRAIN_PID=$!
          
          sleep 10
          
          # Test endpoints
          curl -f http://localhost:8000/metrics || echo "⚠️ Monitoring endpoint issue"
          curl -f -X POST http://localhost:8001/trigger-retrain \
            -H "Content-Type: application/json" \
            -d '{"test": "data"}' || echo "⚠️ Retrain API issue"
          
          # Cleanup
          kill $MONITORING_PID $RETRAIN_PID || true

      # 9. Check for Changes
      - name: Check for Model Changes
        id: check-changes
        run: |
          # Check if model files changed
          if git diff --name-only HEAD~1 | grep -E "(Model/|train\.py|data_)" > /dev/null; then
            echo "model-updated=true" >> $GITHUB_OUTPUT
            echo "📈 Model or training code updated"
          else
            echo "model-updated=false" >> $GITHUB_OUTPUT
            echo "📊 No model changes detected"
          fi

      # 10. Generate Reports
      - name: Generate CI Reports
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "📋 Generating CI reports..."
          make eval
          
          # Create comprehensive CI summary
          cat > ci_summary.md << EOF
          # CI Pipeline Summary
          
          **Date**: $(date)
          **Commit**: ${{ github.sha }}
          **Branch**: ${{ github.ref }}
          
          ## ✅ Completed Checks
          - Code Quality (Black, Flake8, Pylint)
          - Security Scanning (Bandit, Safety)
          - Data Validation
          - Model Training & Validation
          - Data Drift Detection
          - Performance Testing
          - Docker Build & Test
          - Integration Testing
          
          ## 📊 Results
          EOF
          
          # Add model metrics if available
          if [ -f "Results/metrics.txt" ]; then
            echo "### Model Metrics" >> ci_summary.md
            cat Results/metrics.txt >> ci_summary.md
          fi
          
          # Add drift results if available
          if [ -f "drift_results.json" ]; then
            echo "### Drift Detection" >> ci_summary.md
            python -c "
            import json
            with open('drift_results.json', 'r') as f:
                data = json.load(f)
            print(f'- Dataset Drift: {data.get(\"dataset_drift_detected\", \"N/A\")}')
            print(f'- Drift Share: {data.get(\"drift_share\", \"N/A\")}')
            " >> ci_summary.md
          fi
          
          cat ci_summary.md

      # 11. Automated Retraining Decision
      - name: Automated Retraining Check
        run: |
          echo "🤔 Checking if retraining is needed..."
          
          RETRAIN_NEEDED=false
          RETRAIN_REASON=""
          
          # Check if drift detected
          if [ -f "drift_results.json" ]; then
            DRIFT_DETECTED=$(python -c "
            import json
            with open('drift_results.json', 'r') as f:
                data = json.load(f)
            print(str(data.get('dataset_drift_detected', False)).lower())
            ")
            
            if [ "$DRIFT_DETECTED" = "true" ]; then
              RETRAIN_NEEDED=true
              RETRAIN_REASON="Data drift detected"
            fi
          fi
          
          # Check if it's scheduled run and time for retraining
          if [ "${{ github.event_name }}" = "schedule" ]; then
            # Retrain weekly on scheduled runs
            WEEK_DAY=$(date +%u)
            if [ "$WEEK_DAY" = "1" ]; then  # Monday
              RETRAIN_NEEDED=true
              RETRAIN_REASON="$RETRAIN_REASON; Scheduled weekly retraining"
            fi
          fi
          
          if [ "$RETRAIN_NEEDED" = "true" ]; then
            echo "🚨 Retraining needed: $RETRAIN_REASON"
            
            # Perform retraining
            echo "🔄 Starting automated retraining..."
            python train.py --retrain --data_path "Data/synthetic_ctgan_data.csv" --old_data_path "Data/personality_datasert.csv"
            
            echo "✅ Automated retraining completed"
          else
            echo "✅ No retraining needed"
          fi

      # 12. Deployment Decision
      - name: Make Deployment Decision
        id: deployment-decision
        run: |
          SHOULD_DEPLOY=false
          
          # Deploy if on main branch
          if [ "${{ github.ref }}" = "refs/heads/main" ]; then
            SHOULD_DEPLOY=true
          fi
          
          # Deploy if model was updated
          if [ "${{ steps.check-changes.outputs.model-updated }}" = "true" ]; then
            SHOULD_DEPLOY=true
          fi
          
          # Deploy if manual trigger
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            SHOULD_DEPLOY=true
          fi
          
          echo "should-deploy=$SHOULD_DEPLOY" >> $GITHUB_OUTPUT
          
          if [ "$SHOULD_DEPLOY" = "true" ]; then
            echo "✅ Deployment approved"
          else
            echo "⏭️ Deployment skipped"
          fi

      # 13. Update Results
      - name: Update Repository with Results
        if: github.ref == 'refs/heads/main'
        env:
          USER_NAME: ${{ secrets.USER_NAME || 'github-actions[bot]' }}
          USER_EMAIL: ${{ secrets.USER_EMAIL || 'github-actions[bot]@users.noreply.github.com' }}
        run: |
          git config user.name "$USER_NAME"
          git config user.email "$USER_EMAIL"
          
          # Add all results
          git add Results/ Model/ report.md ci_summary.md drift_results.json || true
          git commit -m "🤖 CI: Update training, evaluation and monitoring results [skip ci]" || echo "Nothing to commit"
          git push origin HEAD:main || echo "Nothing to push"

      # 14. Upload Artifacts
      - name: Upload CI Artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: ci-artifacts
          path: |
            Model/
            Results/
            report.md
            ci_summary.md
            drift_results.json
            bandit-report.json
            safety-report.json

